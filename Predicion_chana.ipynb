{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JtgstIPXe1i6"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVR\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_shape (65581, 5, 13) y shape (65581, 13)\n"
     ]
    }
   ],
   "source": [
    "X_corona = np.load('x_covid.npy',allow_pickle=True)\n",
    "y_corona = np.load('y_out.npy',allow_pickle=True)\n",
    "\n",
    "number_of_data_points=X_corona.shape[0]\n",
    "number_of_time=X_corona.shape[1]\n",
    "print(\"x_shape {} y shape {}\".format(X_corona.shape,y_corona.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking data correction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum_all=[]\n",
    "# for i in range(0,100,1):\n",
    "#     (np.linalg.norm(X_corona[i+1,-1,:]-y_corona[i,:]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting the data for sklearn and flatten the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flatten shape (65581, 65)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "    \n",
    "X_corona_flatten=X_corona.reshape((X_corona.shape[0],X_corona.shape[1]*X_corona.shape[2])) \n",
    "print(\"flatten shape {}\".format(X_corona_flatten.shape))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_corona_flatten, y_corona, test_size=0.1, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0Qf967Hqey7Q"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ros1tv/anaconda3/envs/corona_env/lib/python3.8/site-packages/xgboost/data.py:104: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "MultiOutputRegressor\n",
      "****Results****\n",
      "Accuracy: 1.356e+08\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "    #MultiOutputRegressor(SVR(kernel='rbf', C=100, gamma=1, epsilon=.1)),\n",
    "    #MultiOutputRegressor(SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1)),\n",
    "    #MultiOutputRegressor(SVR(kernel='rbf', C=100, gamma=0.01, epsilon=.1)),\n",
    "    #MultiOutputRegressor(SVR(kernel='poly', C=100, gamma='auto', degree=2, epsilon=.1)),\n",
    "    #MultiOutputRegressor(SVR(kernel='poly', C=100, gamma='auto', degree=3, epsilon=.1)),\n",
    "    #MultiOutputRegressor(SVR(kernel='poly', degree=5),n_jobs=-1),\n",
    "    #MultiOutputRegressor(SVR(kernel='poly', degree=9),n_jobs=-1),\n",
    "#     MultiOutputRegressor(xgb.XGBRegressor(max_depth = 50, alpha = 10, \n",
    "#                                           n_estimators = 200,nthread=-1)),\n",
    "    MultiOutputRegressor(xgb.XGBRegressor(max_depth = 10, \n",
    "                                          n_estimators = 250,nthread=-1)),\n",
    "#     MultiOutputRegressor(xgb.XGBRegressor(max_depth = 20, \n",
    "#                                           n_estimators = 500,nthread=-1)),\n",
    "#     #MultiOutputRegressor(SVR(kernel='linear'),n_jobs=-1),\n",
    "#     MultiOutputRegressor(RandomForestRegressor(max_depth=20, random_state=0,n_jobs=-1)),\n",
    "]\n",
    "\n",
    "# Logging for Visual Comparison\n",
    "log_cols=[\"Classifier\", \"Accuracy\", \"Log Loss\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "    print(name)\n",
    "    \n",
    "    print('****Results****')\n",
    "    train_predictions = clf.predict(X_test)\n",
    "    acc = np.linalg.norm(train_predictions-y_test)\n",
    "    mean_acc=np.mean(np.abs(train_predictions-y_test))\n",
    "    print(\"Accuracy: {:.4}\".format(acc))\n",
    "    \n",
    "#     train_predictions = clf.predict_proba(X_test)\n",
    "#     ll = log_loss(y_test, train_predictions)\n",
    "#     print(\"Log Loss: {}\".format(ll))\n",
    "    \n",
    "    log_entry = pd.DataFrame([[name, acc, mean_acc]], columns=log_cols)\n",
    "    log = log.append(log_entry)\n",
    "    \n",
    "print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Log Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultiOutputRegressor</td>\n",
       "      <td>1.355587e+08</td>\n",
       "      <td>16118.94426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Classifier      Accuracy     Log Loss\n",
       "0  MultiOutputRegressor  1.355587e+08  16118.94426"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corona x (65581, 5, 13) y (65581, 13) geo (65581, 5, 7)  shapes\n"
     ]
    }
   ],
   "source": [
    "X_corona_2 = np.load('x_covid.npy',allow_pickle=True)\n",
    "X_geo_2 = np.load('x_geo.npy',allow_pickle=True)\n",
    "y_corona_2 = np.load('y_out.npy',allow_pickle=True)\n",
    "\n",
    "print('corona x {} y {} geo {}  shapes'.format(X_corona_2.shape,y_corona_2.shape,X_geo_2.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65581, 7)\n"
     ]
    }
   ],
   "source": [
    "X_geo_2=X_geo_2[:,0,:]\n",
    "print(X_geo_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flatten shape (65581, 72)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "    \n",
    "X_corona_2=X_corona_2.reshape((X_corona_2.shape[0],X_corona_2.shape[1]*X_corona_2.shape[2]))\n",
    "X_all=np.concatenate((X_corona_2,X_geo_2),axis=1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"flatten shape {}\".format(X_all.shape))\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_all, y_corona_2, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spo1hfa/miniconda3/envs/myenv/lib/python3.7/site-packages/xgboost/data.py:106: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"because it will generate extra copies and increase \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "MultiOutputRegressor\n",
      "****Results****\n",
      "Accuracy: 1.318e+06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spo1hfa/miniconda3/envs/myenv/lib/python3.7/site-packages/xgboost/data.py:106: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"because it will generate extra copies and increase \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "MultiOutputRegressor\n",
      "****Results****\n",
      "Accuracy: 1.19e+06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spo1hfa/miniconda3/envs/myenv/lib/python3.7/site-packages/xgboost/data.py:106: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"because it will generate extra copies and increase \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "MultiOutputRegressor\n",
      "****Results****\n",
      "Accuracy: 1.25e+06\n",
      "==============================\n",
      "MultiOutputRegressor\n",
      "****Results****\n",
      "Accuracy: 5.527e+05\n",
      "==============================\n",
      "MultiOutputRegressor\n",
      "****Results****\n",
      "Accuracy: 4.874e+05\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "    #MultiOutputRegressor(SVR(kernel='rbf', C=100, gamma=1, epsilon=.1)),\n",
    "    #MultiOutputRegressor(SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1)),\n",
    "    #MultiOutputRegressor(SVR(kernel='rbf', C=100, gamma=0.01, epsilon=.1)),\n",
    "    #MultiOutputRegressor(SVR(kernel='poly', C=100, gamma='auto', degree=2, epsilon=.1)),\n",
    "    #MultiOutputRegressor(SVR(kernel='poly', C=100, gamma='auto', degree=3, epsilon=.1)),\n",
    "    #MultiOutputRegressor(SVR(kernel='poly', degree=5),n_jobs=-1),\n",
    "    #MultiOutputRegressor(SVR(kernel='poly', degree=9),n_jobs=-1),\n",
    "    MultiOutputRegressor(xgb.XGBRegressor(max_depth = 50, alpha = 10, \n",
    "                                          n_estimators = 200,nthread=-1)),\n",
    "    MultiOutputRegressor(xgb.XGBRegressor(max_depth = 10, \n",
    "                                          n_estimators = 250,nthread=-1)),\n",
    "    MultiOutputRegressor(xgb.XGBRegressor(max_depth = 20, \n",
    "                                          n_estimators = 500,nthread=-1)),\n",
    "    #MultiOutputRegressor(SVR(kernel='linear'),n_jobs=-1),\n",
    "    MultiOutputRegressor(RandomForestRegressor(max_depth=20, random_state=0,n_jobs=-1)),\n",
    "    MultiOutputRegressor(RandomForestRegressor(max_depth=40, random_state=0,n_jobs=-1))\n",
    "]\n",
    "\n",
    "# Logging for Visual Comparison\n",
    "log_cols=[\"Classifier\", \"Accuracy\", \"Log Loss\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train_2, y_train_2)\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "    print(name)\n",
    "    \n",
    "    print('****Results****')\n",
    "    train_predictions = clf.predict(X_test_2)\n",
    "    acc = np.linalg.norm(train_predictions-y_test_2)\n",
    "    mean_acc=np.mean(np.abs(train_predictions-y_test_2))\n",
    "    print(\"Accuracy: {:.4}\".format(acc))\n",
    "    \n",
    "#     train_predictions = clf.predict_proba(X_test)\n",
    "#     ll = log_loss(y_test, train_predictions)\n",
    "#     print(\"Log Loss: {}\".format(ll))\n",
    "    \n",
    "    log_entry_2 = pd.DataFrame([[name, acc, mean_acc]], columns=log_cols)\n",
    "    log_2 = log.append(log_entry_2)\n",
    "    \n",
    "print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train for all features (geo, policies, corona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corona x (65581, 5, 13) y (65581, 13) geo (65581, 5, 7) policies shapes (65581, 5, 12)\n"
     ]
    }
   ],
   "source": [
    "x_corona_3 = np.load('x_covid.npy',allow_pickle=True)\n",
    "x_geo_3 = np.load('x_geo.npy',allow_pickle=True)\n",
    "x_policies_3 = np.load('x_policies.npy',allow_pickle=True)\n",
    "\n",
    "y_corona_3 = np.load('y_out.npy',allow_pickle=True)\n",
    "\n",
    "print('corona x {} y {} geo {} policies shapes {}'.format(x_corona_3.shape,y_corona_3.shape,x_geo_3.shape,x_policies_3.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flatten shape (65581, 132)\n",
      "total num features:132\n"
     ]
    }
   ],
   "source": [
    "x_geo_single = X_geo_3[:, 0, :]\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_corona_policies = np.concatenate((x_corona_3, x_policies_3), axis = 2)\n",
    "x_flatten_corona_policies = x_corona_policies.reshape(x_corona_3.shape[0], (x_corona_policies.shape[1]*x_corona_policies.shape[2]))\n",
    "\n",
    "x_all_3 = np.concatenate((x_flatten_corona_policies, x_geo_single), axis=1)\n",
    "\n",
    "print(\"flatten shape {}\".format(x_all_3.shape))\n",
    "print(f\"total num features:{5*13+7+5*12}\")\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(x_all_3, y_corona_3, test_size=0.1, random_state=42,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    #MultiOutputRegressor(SVR(kernel='rbf', C=100, gamma=1, epsilon=.1)),\n",
    "    #MultiOutputRegressor(SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1)),\n",
    "    #MultiOutputRegressor(SVR(kernel='rbf', C=100, gamma=0.01, epsilon=.1)),\n",
    "    #MultiOutputRegressor(SVR(kernel='poly', C=100, gamma='auto', degree=2, epsilon=.1)),\n",
    "    #MultiOutputRegressor(SVR(kernel='poly', C=100, gamma='auto', degree=3, epsilon=.1)),\n",
    "    #MultiOutputRegressor(SVR(kernel='poly', degree=5),n_jobs=-1),\n",
    "    MultiOutputRegressor(SVR(kernel='poly', degree=9),n_jobs=-1),\n",
    "#     MultiOutputRegressor(xgb.XGBRegressor(max_depth = 50, alpha = 10, \n",
    "#                                           n_estimators = 200,nthread=-1)),\n",
    "#     MultiOutputRegressor(xgb.XGBRegressor(max_depth = 10, \n",
    "#                                           n_estimators = 250,nthread=-1)),\n",
    "#     MultiOutputRegressor(xgb.XGBRegressor(max_depth = 20, \n",
    "#                                           n_estimators = 500,nthread=-1)),\n",
    "    #MultiOutputRegressor(SVR(kernel='linear'),n_jobs=-1),\n",
    "    MultiOutputRegressor(RandomForestRegressor(max_depth=60, random_state=0,n_jobs=-1)),\n",
    "    MultiOutputRegressor(RandomForestRegressor(max_depth=100, random_state=0,n_jobs=-1))\n",
    "]\n",
    "\n",
    "# Logging for Visual Comparison\n",
    "log_cols=[\"Classifier\", \"Accuracy\", \"Log Loss\"]\n",
    "log3 = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train_3, y_train_3)\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "    print(name)\n",
    "    \n",
    "    print('****Results****')\n",
    "    train_predictions = clf.predict(X_test_3)\n",
    "    acc = np.linalg.norm(train_predictions-y_test_3)\n",
    "    mean_acc=np.mean(np.abs(train_predictions-y_test_3))\n",
    "    print(\"Accuracy: {:.4}\".format(acc))\n",
    "    \n",
    "#     train_predictions = clf.predict_proba(X_test)\n",
    "#     ll = log_loss(y_test, train_predictions)\n",
    "#     print(\"Log Loss: {}\".format(ll))\n",
    "    \n",
    "    log_entry_2 = pd.DataFrame([[name, acc, mean_acc]], columns=log_cols)\n",
    "    log3 = log3.append(log_entry_2)\n",
    "    \n",
    "print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Log Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultiOutputRegressor</td>\n",
       "      <td>1.352767e+08</td>\n",
       "      <td>16120.191077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultiOutputRegressor</td>\n",
       "      <td>1.366866e+08</td>\n",
       "      <td>16157.520081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultiOutputRegressor</td>\n",
       "      <td>1.369528e+08</td>\n",
       "      <td>16188.338814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Classifier      Accuracy      Log Loss\n",
       "0  MultiOutputRegressor  1.352767e+08  16120.191077\n",
       "0  MultiOutputRegressor  1.366866e+08  16157.520081\n",
       "0  MultiOutputRegressor  1.369528e+08  16188.338814"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "id": "ALxwCIsHlrD6",
    "outputId": "295a5a6d-9705-4aa8-a36c-05d48955c231"
   },
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_forecasting.metrics import QuantileLoss\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vz6KLvk2lpDb"
   },
   "outputs": [],
   "source": [
    "x# load data\n",
    "data = ...\n",
    "\n",
    "# define dataset\n",
    "max_encoder_length = 36\n",
    "max_prediction_length = 6\n",
    "training_cutoff = \"YYYY-MM-DD\"  # day for cutoff\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    data[lambda x: x.date <= training_cutoff],\n",
    "    time_idx= ...,\n",
    "    target= ...,\n",
    "    group_ids=[ ... ],\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[ ... ],\n",
    "    static_reals=[ ... ],\n",
    "    time_varying_known_categoricals=[ ... ],\n",
    "    time_varying_known_reals=[ ... ],\n",
    "    time_varying_unknown_categoricals=[ ... ],\n",
    "    time_varying_unknown_reals=[ ... ],\n",
    ")\n",
    "\n",
    "\n",
    "validation = TimeSeriesDataSet.from_dataset(training, data, min_prediction_idx=training.index.time.max() + 1, stop_randomization=True)\n",
    "batch_size = 128\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=2)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size, num_workers=2)\n",
    "\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=1, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    gpus=0,\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=30,\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    ")\n",
    "\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=32,\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=16,\n",
    "    output_size=7,\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=2,\n",
    "    reduce_on_plateau_patience=4\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")\n",
    "\n",
    "# find optimal learning rate\n",
    "res = trainer.lr_find(\n",
    "    tft, train_dataloader=train_dataloader, val_dataloaders=val_dataloader, early_stop_threshold=1000.0, max_lr=0.3,\n",
    ")\n",
    "\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()\n",
    "\n",
    "trainer.fit(\n",
    "    tft, train_dataloader=train_dataloader, val_dataloaders=val_dataloader,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
